{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1>[문제1]Fashion MNIST 데이터 정규화를 위한 Mean과 Std 값 찾기",
   "id": "a2e05cc6bbd6553"
  },
  {
   "cell_type": "code",
   "id": "ebdaa7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:46:32.876971Z",
     "start_time": "2024-11-22T15:46:27.890857Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c0cfb49d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:46:36.304257Z",
     "start_time": "2024-11-22T15:46:36.287253Z"
    }
   },
   "source": [
    "base_path = os.path.join(os.path.pardir, 'data', 'fashion_mnist')\n",
    "print(base_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\fashion_mnist\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97aeb825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 26421880/26421880 [00:03<00:00, 6639572.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 29515/29515 [00:00<00:00, 106709.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 4422102/4422102 [00:03<00:00, 1368901.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5148/5148 [00:00<00:00, 14112599.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/fashion_mnist/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_dataset = datasets.FashionMNIST(base_path, train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476decf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = torch.cat([fashion_mnist_dataset[i][0] for i in range(len(fashion_mnist_dataset))], dim=0)\n",
    "\n",
    "# 평균과 표준편차 계산\n",
    "mean = all_images.mean().item()\n",
    "std = all_images.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ec8245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.28604060411453247\n",
      "Standard Deviation: 0.3530242443084717\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", mean)\n",
    "print(\"Standard Deviation:\", std)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mean은 0.2860..., Std는 0.3530...",
   "id": "e15b4b6a1b62653e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<H1>[문제2]Fashion MNIST 데이터에 대하여 CNN학습 시키기",
   "id": "e12473bd2375104d"
  },
  {
   "cell_type": "code",
   "id": "29b0a310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:46:51.431566Z",
     "start_time": "2024-11-22T15:46:51.414563Z"
    }
   },
   "source": [
    "#fashion_mnist데이터 불러오기 \n",
    "def get_fashion_mnist_data():\n",
    "    \n",
    "    #fashion mnist traindata를 불러오기\n",
    "    f_mnist_train = datasets.FashionMNIST(base_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    print(\"Sample Shape:\", f_mnist_train[0][0].shape)\n",
    "    def get_num_cpu_cores():\n",
    "        import multiprocessing\n",
    "        return multiprocessing.cpu_count()\n",
    "    num_data_loading_workers = get_num_cpu_cores()\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "    \n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size, shuffle=False,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "    \n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3530),\n",
    "    )\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b079eeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:46:52.935902Z",
     "start_time": "2024-11-22T15:46:52.920899Z"
    }
   },
   "source": [
    "#fashion_test데이터 불러오기\n",
    "def get_fashion_mnist_test_data():\n",
    "    f_mnist_test_images = datasets.FashionMNIST(base_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(base_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3530),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002544d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Sample Shape: torch.Size([1, 28, 28])\n",
      "\n",
      "Num Test Samples:  10000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'batch_size': 2048,\n",
    "}\n",
    "wandb.init(mode='disabled',config=config)\n",
    "train_data_loader, validation_data_loader, f_mnist_transforms = get_fashion_mnist_data() \n",
    "print()\n",
    "f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca1e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b24dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    " #가장 기본적인 모델 \n",
    "class FirstModel(nn.Module):\n",
    "    def __init__(self, in_channels, n_output=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=64,kernel_size=(3,3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(out_channels=64,kernel_size=(3,3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(out_features=n_output),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        X = self.model(X)\n",
    "        return X\n",
    "#모델 가져오는 함수\n",
    "def get_cnn_model():\n",
    "    model = FirstModel(in_channels=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262b41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "#제공된 DeltaTemplate 사용\n",
    "class DeltaTemplate(Template):\n",
    "    delimiter = \"%\"\n",
    "\n",
    "    def strfdelta(tdelta, fmt):\n",
    "        d = {\"D\": tdelta.days}\n",
    "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
    "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
    "        t = DeltaTemplate(fmt)\n",
    "        return t.substitute(**d)\n",
    "    \n",
    "def strfdelta(td, fmt):\n",
    "\n",
    "    # Get the timedelta’s sign and absolute number of seconds.\n",
    "    sign = \"-\" if td.days < 0 else \"+\"\n",
    "    secs = abs(td).total_seconds()\n",
    "\n",
    "    # Break the seconds into more readable quantities.\n",
    "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
    "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
    "    mins, secs = divmod(rem, 60)\n",
    "\n",
    "    # Format (as per above answers) and return the result string.\n",
    "    t = DeltaTemplate(fmt)\n",
    "    return t.substitute(\n",
    "        s=sign,\n",
    "        D=\"{:d}\".format(int(days)),\n",
    "        H=\"{:02d}\".format(int(hours)),\n",
    "        M=\"{:02d}\".format(int(mins)),\n",
    "        S=\"{:02d}\".format(int(secs)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61b59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#제공된 EarlyStopping클래스 사용\n",
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=10, delta=0.00001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.delta = delta\n",
    "\n",
    "        self.val_loss_min = None\n",
    "        self.file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "        )\n",
    "        self.latest_file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "        )\n",
    "\n",
    "    def check_and_save(self, new_validation_loss, model):\n",
    "        early_stop = False\n",
    "\n",
    "        if self.val_loss_min is None:\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            message = f'Early stopping is stated!'\n",
    "        elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "            message = f'V_loss decreased ({self.val_loss_min:7.5f} --> {new_validation_loss:7.5f}). Saving model...'\n",
    "            self.save_checkpoint(new_validation_loss, model)\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "            if self.counter >= self.patience:\n",
    "                early_stop = True\n",
    "                message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "        return message, early_stop\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), self.file_path)\n",
    "        torch.save(model.state_dict(), self.latest_file_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0421b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#제공된 ClassificationTrainer클래스를 조금 수정해서 사용\n",
    "class Trainer:\n",
    "    def __init__(self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms, run_time_str, wandb, device, checkpoint_file_path):\n",
    "        self.project_name = project_name\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.validation_data_loader = validation_data_loader\n",
    "        self.transforms = transforms\n",
    "        self.run_time_str = run_time_str\n",
    "        self.wandb = wandb\n",
    "        self.device = device\n",
    "        self.checkpoint_file_path = checkpoint_file_path\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def do_train(self):\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        num_trains = 0\n",
    "        num_correct = 0\n",
    "        num_trained_samples = 0\n",
    "        for images, labels in self.train_data_loader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            if self.transforms:\n",
    "                images = self.transforms(images)\n",
    "            \n",
    "            train_output = self.model(images)\n",
    "            loss = self.loss_fn(train_output, labels)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_predited = torch.argmax(train_output, dim=-1)\n",
    "            #Accuracy를 구하기위해서 label과 predicted 맞힌 개수\n",
    "            num_correct += (train_predited == labels).sum().item()\n",
    "            num_trained_samples += len(images)\n",
    "            num_trains += 1\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        train_loss /= num_trains\n",
    "        train_accuracy = 100 * num_correct / num_trained_samples\n",
    "        return train_loss, train_accuracy\n",
    "    def do_validation(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        validation_loss = 0.0\n",
    "        num_validations = 0\n",
    "        num_correct = 0\n",
    "        num_validation_samples = 0\n",
    "        for images, labels in self.validation_data_loader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            if self.transforms:\n",
    "                images = self.transforms(images)\n",
    "            output_validation = self.model(images)\n",
    "            validation_loss += self.loss_fn(output_validation, labels).item()\n",
    "            _, predicted = torch.max(output_validation.data, 1)\n",
    "            num_validation_samples += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum().item()\n",
    "            num_validations+=1\n",
    "        \n",
    "        validation_loss /= num_validations\n",
    "        validation_accuracy = 100 * num_correct / num_validation_samples\n",
    "        \n",
    "        return validation_loss, validation_accuracy\n",
    "    \n",
    "    def train_loop(self):\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=self.wandb.config.early_stop_patience,\n",
    "            delta=self.wandb.config.early_stop_delta,\n",
    "            project_name=self.project_name,\n",
    "            checkpoint_file_path=self.checkpoint_file_path,\n",
    "            run_time_str=self.run_time_str,\n",
    "        )\n",
    "        num_epochs = self.wandb.config.epochs\n",
    "        training_start_time = datetime.now()\n",
    "        for epoch in range(1,num_epochs+1):\n",
    "            train_loss, train_accuracy = self.do_train()\n",
    "            if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "                validation_loss, validation_accuracy = self.do_validation()\n",
    "                \n",
    "                elapsed_time = datetime.now() - training_start_time\n",
    "                epoch_per_second = 0 if elapsed_time == 0 else epoch / elapsed_time.seconds\n",
    "                \n",
    "                message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "                print(\n",
    "                    f\"[Epoch {epoch:>3}] \"\n",
    "                    f\"T_loss: {train_loss:7.5f}, \"\n",
    "                    f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "                    f\"V_loss: {validation_loss:7.5f}, \"\n",
    "                    f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "                    f\"{message} | \"\n",
    "                    f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "                    f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "                )\n",
    "                self.wandb.log({\n",
    "                    \"Epoch\": epoch,\n",
    "                    \"Training loss\": train_loss,\n",
    "                    \"Training accuracy\": train_accuracy,\n",
    "                    \"Validation loss\": validation_loss,\n",
    "                    \"Validation accuracy (%)\": validation_accuracy,\n",
    "                    \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "                })\n",
    "                if early_stop:\n",
    "                    break\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f0c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2af4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#하이퍼 파라미터 설정\n",
    "config = {\n",
    "    'epochs': 1000, #epoch는 1000\n",
    "    'batch_size': 128,\n",
    "    'validation_intervals': 10, #train 5번당 validation1번\n",
    "    'learning_rate': 0.001, #learning rate는 0.001\n",
    "    'early_stop_patience': 10, #더이상 validation loss가 10번동안 줄지 않으면 학습 중지\n",
    "    'early_stop_delta': 0.0001 \n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #gpu 사용가능 여부 체크\n",
    "project_name = 'Fashion_MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec84077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstModel_addDropout(nn.Module):\n",
    "    def __init__(self, in_channels, n_output=10):\n",
    "        super().__init__()\n",
    "        # 컨볼루션 층 2번 리니어층 1번하는 모델\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=64,kernel_size=(3,3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(out_channels=64,kernel_size=(3,3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            #기본 모델에 Dropout을 추가함\n",
    "            nn.Dropout(0.5), \n",
    "            nn.LazyLinear(out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(out_features=n_output),\n",
    "            #기본 모델에 Dropout을 추가함\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        X = self.model(X)\n",
    "        return X\n",
    "def get_fisrtmodel_addDropout():\n",
    "    return FirstModel_addDropout(in_channels=1, n_output=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5926ef22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5e781a4b1f4371a2b8aa1041f4c446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113101409541236, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/link_dl/wandb/run-20241122_110637-iys6tete</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/iys6tete' target=\"_blank\">firstmodel_addDropout</a></strong> to <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/iys6tete' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/iys6tete</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 2.06943, T_accuracy: 38.0073 | V_loss: 1.72327, V_accuracy: 75.2800 | Early stopping is stated! | T_time: 00:00:04, T_speed: 0.250\n",
      "[Epoch   5] T_loss: 1.93145, T_accuracy: 50.7200 | V_loss: 1.62567, V_accuracy: 84.8000 | V_loss decreased (1.72327 --> 1.62567). Saving model... | T_time: 00:00:14, T_speed: 0.357\n",
      "[Epoch  10] T_loss: 1.91426, T_accuracy: 52.3509 | V_loss: 1.59557, V_accuracy: 87.0600 | V_loss decreased (1.62567 --> 1.59557). Saving model... | T_time: 00:00:27, T_speed: 0.370\n",
      "[Epoch  15] T_loss: 1.90663, T_accuracy: 53.0891 | V_loss: 1.58598, V_accuracy: 87.7800 | V_loss decreased (1.59557 --> 1.58598). Saving model... | T_time: 00:00:40, T_speed: 0.375\n",
      "[Epoch  20] T_loss: 1.90253, T_accuracy: 53.4673 | V_loss: 1.58144, V_accuracy: 88.5000 | V_loss decreased (1.58598 --> 1.58144). Saving model... | T_time: 00:00:53, T_speed: 0.377\n",
      "[Epoch  25] T_loss: 1.90076, T_accuracy: 53.3855 | V_loss: 1.56974, V_accuracy: 89.4400 | V_loss decreased (1.58144 --> 1.56974). Saving model... | T_time: 00:01:06, T_speed: 0.379\n",
      "[Epoch  30] T_loss: 1.89592, T_accuracy: 54.0091 | V_loss: 1.56631, V_accuracy: 89.7200 | V_loss decreased (1.56974 --> 1.56631). Saving model... | T_time: 00:01:19, T_speed: 0.380\n",
      "[Epoch  35] T_loss: 1.89186, T_accuracy: 54.3309 | V_loss: 1.56335, V_accuracy: 90.2800 | V_loss decreased (1.56631 --> 1.56335). Saving model... | T_time: 00:01:32, T_speed: 0.380\n",
      "[Epoch  40] T_loss: 1.88731, T_accuracy: 54.7127 | V_loss: 1.55838, V_accuracy: 90.5000 | V_loss decreased (1.56335 --> 1.55838). Saving model... | T_time: 00:01:45, T_speed: 0.381\n",
      "[Epoch  45] T_loss: 1.88612, T_accuracy: 54.9455 | V_loss: 1.55227, V_accuracy: 91.1600 | V_loss decreased (1.55838 --> 1.55227). Saving model... | T_time: 00:01:58, T_speed: 0.381\n",
      "[Epoch  50] T_loss: 1.88433, T_accuracy: 55.0764 | V_loss: 1.55031, V_accuracy: 91.1000 | V_loss decreased (1.55227 --> 1.55031). Saving model... | T_time: 00:02:11, T_speed: 0.382\n",
      "[Epoch  55] T_loss: 1.88406, T_accuracy: 55.1582 | V_loss: 1.55221, V_accuracy: 91.0400 | Early stopping counter: 1 out of 10 | T_time: 00:02:24, T_speed: 0.382\n",
      "[Epoch  60] T_loss: 1.88066, T_accuracy: 55.3636 | V_loss: 1.55252, V_accuracy: 91.1800 | Early stopping counter: 2 out of 10 | T_time: 00:02:37, T_speed: 0.382\n",
      "[Epoch  65] T_loss: 1.88279, T_accuracy: 55.1855 | V_loss: 1.54995, V_accuracy: 91.2600 | V_loss decreased (1.55031 --> 1.54995). Saving model... | T_time: 00:02:50, T_speed: 0.382\n",
      "[Epoch  70] T_loss: 1.88027, T_accuracy: 55.4400 | V_loss: 1.54708, V_accuracy: 91.5400 | V_loss decreased (1.54995 --> 1.54708). Saving model... | T_time: 00:03:03, T_speed: 0.383\n",
      "[Epoch  75] T_loss: 1.88192, T_accuracy: 55.2836 | V_loss: 1.54848, V_accuracy: 91.7200 | Early stopping counter: 1 out of 10 | T_time: 00:03:16, T_speed: 0.383\n",
      "[Epoch  80] T_loss: 1.87752, T_accuracy: 55.6545 | V_loss: 1.54621, V_accuracy: 91.7600 | V_loss decreased (1.54708 --> 1.54621). Saving model... | T_time: 00:03:29, T_speed: 0.383\n",
      "[Epoch  85] T_loss: 1.87818, T_accuracy: 55.7418 | V_loss: 1.54192, V_accuracy: 92.3400 | V_loss decreased (1.54621 --> 1.54192). Saving model... | T_time: 00:03:42, T_speed: 0.383\n",
      "[Epoch  90] T_loss: 1.87591, T_accuracy: 56.0255 | V_loss: 1.54240, V_accuracy: 92.2600 | Early stopping counter: 1 out of 10 | T_time: 00:03:55, T_speed: 0.383\n",
      "[Epoch  95] T_loss: 1.87632, T_accuracy: 55.6309 | V_loss: 1.54340, V_accuracy: 92.1000 | Early stopping counter: 2 out of 10 | T_time: 00:04:08, T_speed: 0.383\n",
      "[Epoch 100] T_loss: 1.87551, T_accuracy: 55.9855 | V_loss: 1.54031, V_accuracy: 92.0800 | V_loss decreased (1.54192 --> 1.54031). Saving model... | T_time: 00:04:20, T_speed: 0.385\n",
      "[Epoch 105] T_loss: 1.87619, T_accuracy: 55.9491 | V_loss: 1.54124, V_accuracy: 92.3000 | Early stopping counter: 1 out of 10 | T_time: 00:04:33, T_speed: 0.385\n",
      "[Epoch 110] T_loss: 1.87267, T_accuracy: 56.1455 | V_loss: 1.53940, V_accuracy: 92.5600 | V_loss decreased (1.54031 --> 1.53940). Saving model... | T_time: 00:04:46, T_speed: 0.385\n",
      "[Epoch 115] T_loss: 1.87207, T_accuracy: 56.1273 | V_loss: 1.53807, V_accuracy: 92.4000 | V_loss decreased (1.53940 --> 1.53807). Saving model... | T_time: 00:04:59, T_speed: 0.385\n",
      "[Epoch 120] T_loss: 1.87148, T_accuracy: 56.4727 | V_loss: 1.53702, V_accuracy: 92.7000 | V_loss decreased (1.53807 --> 1.53702). Saving model... | T_time: 00:05:12, T_speed: 0.385\n",
      "[Epoch 125] T_loss: 1.86825, T_accuracy: 56.5400 | V_loss: 1.53885, V_accuracy: 92.4000 | Early stopping counter: 1 out of 10 | T_time: 00:05:25, T_speed: 0.385\n",
      "[Epoch 130] T_loss: 1.87300, T_accuracy: 56.2473 | V_loss: 1.54068, V_accuracy: 92.2600 | Early stopping counter: 2 out of 10 | T_time: 00:05:38, T_speed: 0.385\n",
      "[Epoch 135] T_loss: 1.87237, T_accuracy: 56.1236 | V_loss: 1.53956, V_accuracy: 92.2600 | Early stopping counter: 3 out of 10 | T_time: 00:05:51, T_speed: 0.385\n",
      "[Epoch 140] T_loss: 1.87547, T_accuracy: 55.7291 | V_loss: 1.53695, V_accuracy: 92.6200 | Early stopping counter: 4 out of 10 | T_time: 00:06:04, T_speed: 0.385\n",
      "[Epoch 145] T_loss: 1.87048, T_accuracy: 56.4127 | V_loss: 1.53470, V_accuracy: 92.7800 | V_loss decreased (1.53702 --> 1.53470). Saving model... | T_time: 00:06:17, T_speed: 0.385\n",
      "[Epoch 150] T_loss: 1.86798, T_accuracy: 56.4836 | V_loss: 1.53624, V_accuracy: 92.7000 | Early stopping counter: 1 out of 10 | T_time: 00:06:30, T_speed: 0.385\n",
      "[Epoch 155] T_loss: 1.86996, T_accuracy: 56.4545 | V_loss: 1.53245, V_accuracy: 93.1400 | V_loss decreased (1.53470 --> 1.53245). Saving model... | T_time: 00:06:43, T_speed: 0.385\n",
      "[Epoch 160] T_loss: 1.86589, T_accuracy: 56.8764 | V_loss: 1.53378, V_accuracy: 93.0600 | Early stopping counter: 1 out of 10 | T_time: 00:06:56, T_speed: 0.385\n",
      "[Epoch 165] T_loss: 1.87052, T_accuracy: 56.4527 | V_loss: 1.53507, V_accuracy: 92.8000 | Early stopping counter: 2 out of 10 | T_time: 00:07:09, T_speed: 0.385\n",
      "[Epoch 170] T_loss: 1.86632, T_accuracy: 56.7691 | V_loss: 1.53397, V_accuracy: 92.8000 | Early stopping counter: 3 out of 10 | T_time: 00:07:22, T_speed: 0.385\n",
      "[Epoch 175] T_loss: 1.86912, T_accuracy: 56.4818 | V_loss: 1.53490, V_accuracy: 92.6400 | Early stopping counter: 4 out of 10 | T_time: 00:07:35, T_speed: 0.385\n",
      "[Epoch 180] T_loss: 1.86780, T_accuracy: 56.7800 | V_loss: 1.53338, V_accuracy: 92.9400 | Early stopping counter: 5 out of 10 | T_time: 00:07:48, T_speed: 0.385\n",
      "[Epoch 185] T_loss: 1.86743, T_accuracy: 56.8309 | V_loss: 1.53442, V_accuracy: 92.7800 | Early stopping counter: 6 out of 10 | T_time: 00:08:01, T_speed: 0.385\n",
      "[Epoch 190] T_loss: 1.86559, T_accuracy: 56.8164 | V_loss: 1.53275, V_accuracy: 92.8800 | Early stopping counter: 7 out of 10 | T_time: 00:08:14, T_speed: 0.385\n",
      "[Epoch 195] T_loss: 1.86457, T_accuracy: 56.9745 | V_loss: 1.53411, V_accuracy: 92.9000 | Early stopping counter: 8 out of 10 | T_time: 00:08:27, T_speed: 0.385\n",
      "[Epoch 200] T_loss: 1.86144, T_accuracy: 57.3855 | V_loss: 1.53372, V_accuracy: 92.8800 | Early stopping counter: 9 out of 10 | T_time: 00:08:40, T_speed: 0.385\n",
      "[Epoch 205] T_loss: 1.86080, T_accuracy: 57.3200 | V_loss: 1.53328, V_accuracy: 92.9600 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 00:08:53, T_speed: 0.385\n",
      "Final training time: 00:08:53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Training accuracy</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████▇████████████</td></tr><tr><td>Training loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>Validation accuracy (%)</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>Validation loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>205</td></tr><tr><td>Training accuracy</td><td>57.32</td></tr><tr><td>Training loss</td><td>1.8608</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.38462</td></tr><tr><td>Validation accuracy (%)</td><td>92.96</td></tr><tr><td>Validation loss</td><td>1.53328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firstmodel_addDropout</strong> at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/iys6tete' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/iys6tete</a><br/> View project at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241122_110637-iys6tete/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델을 저장하기위한 path\n",
    "first_model_addDropout_path = os.path.join('checkpoint_dropout')\n",
    "name = 'firstmodel_addDropout'\n",
    "wandb.init(\n",
    "    mode='online',\n",
    "    project=project_name,\n",
    "    notes='Fashion_MNIST with various models',\n",
    "    name=name,\n",
    "    config=config,\n",
    ")\n",
    "#모델 불러오는 함수 호출\n",
    "dropout_model = get_fisrtmodel_addDropout()\n",
    "dropout_model.to(device)\n",
    "#adam optimizer를 사용\n",
    "optimizer = torch.optim.Adam(dropout_model.parameters(), lr=wandb.config.learning_rate)\n",
    "classification_trainer = Trainer(\n",
    "    project_name=project_name,model=dropout_model, optimizer=optimizer,train_data_loader=train_data_loader, validation_data_loader=validation_data_loader,\n",
    "    transforms=f_mnist_transforms, run_time_str=run_time_str,wandb=wandb,device=device,checkpoint_file_path=first_model_addDropout_path\n",
    ")\n",
    "#학습 시작\n",
    "classification_trainer.train_loop()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a206c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "FirstModel_addDropout                    --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "├─Sequential: 1-1                        --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "│    └─Conv2d: 2-1                       [3, 3]                    [1, 1, 28, 28]            [1, 64, 26, 26]           640                       432,640\n",
       "│    └─MaxPool2d: 2-2                    [2, 2]                    [1, 64, 26, 26]           [1, 64, 13, 13]           --                        --\n",
       "│    └─ReLU: 2-3                         --                        [1, 64, 13, 13]           [1, 64, 13, 13]           --                        --\n",
       "│    └─Conv2d: 2-4                       [3, 3]                    [1, 64, 13, 13]           [1, 64, 11, 11]           36,928                    4,468,288\n",
       "│    └─MaxPool2d: 2-5                    [2, 2]                    [1, 64, 11, 11]           [1, 64, 5, 5]             --                        --\n",
       "│    └─ReLU: 2-6                         --                        [1, 64, 5, 5]             [1, 64, 5, 5]             --                        --\n",
       "│    └─Flatten: 2-7                      --                        [1, 64, 5, 5]             [1, 1600]                 --                        --\n",
       "│    └─Dropout: 2-8                      --                        [1, 1600]                 [1, 1600]                 --                        --\n",
       "│    └─Linear: 2-9                       --                        [1, 1600]                 [1, 128]                  204,928                   204,928\n",
       "│    └─ReLU: 2-10                        --                        [1, 128]                  [1, 128]                  --                        --\n",
       "│    └─Linear: 2-11                      --                        [1, 128]                  [1, 10]                   1,290                     1,290\n",
       "│    └─Dropout: 2-12                     --                        [1, 10]                   [1, 10]                   --                        --\n",
       "│    └─Softmax: 2-13                     --                        [1, 10]                   [1, 10]                   --                        --\n",
       "=====================================================================================================================================================================\n",
       "Total params: 243,786\n",
       "Trainable params: 243,786\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 5.11\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.41\n",
       "Params size (MB): 0.98\n",
       "Estimated Total Size (MB): 1.39\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=dropout_model, input_size=(1, 1, 28, 28),\n",
    "        col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], dtypes=[torch.float] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7c1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_model():\n",
    "    class Residual(nn.Module):\n",
    "        def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.LazyConv2d(out_channels=num_channels, kernel_size=3, padding=1, stride=strides)\n",
    "            self.conv2 = nn.LazyConv2d(out_channels=num_channels, kernel_size=3, padding=1)\n",
    "            if use_1x1conv:\n",
    "                self.conv3 = nn.LazyConv2d(out_channels=num_channels, kernel_size=1, stride=strides)\n",
    "            else:\n",
    "                self.conv3 = None\n",
    "            self.bn1 = nn.LazyBatchNorm2d()\n",
    "            self.bn2 = nn.LazyBatchNorm2d()\n",
    "\n",
    "        def forward(self, X):\n",
    "            Y = torch.relu(self.bn1(self.conv1(X)))\n",
    "            Y = self.bn2(self.conv2(Y))\n",
    "            if self.conv3:\n",
    "                X = self.conv3(X)\n",
    "            Y += X\n",
    "            return torch.relu(Y)\n",
    "\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self, arch, n_outputs=10):\n",
    "            super(ResNet, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Sequential(\n",
    "                    nn.LazyConv2d(out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "                    nn.LazyBatchNorm2d(),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.25),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Add residual blocks\n",
    "            for i, (num_residuals, num_channels) in enumerate(arch):\n",
    "                self.model.add_module(\n",
    "                    name=f'block_{i}', \n",
    "                    module=self.block(num_residuals, num_channels, first_block=(i == 0))\n",
    "                )\n",
    "            \n",
    "            # Add the final classification layers\n",
    "            self.model.add_module(\n",
    "                name='last',\n",
    "                module=nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Dropout(0.25),\n",
    "                    nn.LazyLinear(n_outputs),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        def block(self, num_residuals, num_channels, first_block=False):\n",
    "            blk = []\n",
    "            for i in range(num_residuals):\n",
    "                if i == 0 and not first_block:\n",
    "                    blk.append(Residual(num_channels=num_channels, use_1x1conv=True, strides=2))\n",
    "                else:\n",
    "                    blk.append(Residual(num_channels=num_channels))\n",
    "            return nn.Sequential(*blk)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    my_model = ResNet(arch=((2, 64), (2, 128), (2, 256), (2, 512)), n_outputs=10)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e0397c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8373bb7307cf4a15b1216265eff8aa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113016224569745, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/link_dl/wandb/run-20241122_113350-2ktz7942</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/2ktz7942' target=\"_blank\">ResnetModel</a></strong> to <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/2ktz7942' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/2ktz7942</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 0.78017, T_accuracy: 72.6764 | V_loss: 0.67305, V_accuracy: 77.0000 | Early stopping is stated! | T_time: 00:00:04, T_speed: 0.250\n",
      "[Epoch  10] T_loss: 0.17812, T_accuracy: 93.2891 | V_loss: 0.31496, V_accuracy: 88.7200 | V_loss decreased (0.67305 --> 0.31496). Saving model... | T_time: 00:00:41, T_speed: 0.244\n",
      "[Epoch  20] T_loss: 0.10044, T_accuracy: 96.1782 | V_loss: 0.36200, V_accuracy: 89.0400 | Early stopping counter: 1 out of 10 | T_time: 00:01:23, T_speed: 0.241\n",
      "[Epoch  30] T_loss: 0.06360, T_accuracy: 97.5782 | V_loss: 0.38660, V_accuracy: 89.7400 | Early stopping counter: 2 out of 10 | T_time: 00:02:05, T_speed: 0.240\n",
      "[Epoch  40] T_loss: 0.03995, T_accuracy: 98.5036 | V_loss: 0.38108, V_accuracy: 90.7200 | Early stopping counter: 3 out of 10 | T_time: 00:02:46, T_speed: 0.241\n",
      "[Epoch  50] T_loss: 0.02596, T_accuracy: 99.0164 | V_loss: 0.48603, V_accuracy: 90.1400 | Early stopping counter: 4 out of 10 | T_time: 00:03:28, T_speed: 0.240\n",
      "[Epoch  60] T_loss: 0.02555, T_accuracy: 99.0818 | V_loss: 0.45956, V_accuracy: 89.6000 | Early stopping counter: 5 out of 10 | T_time: 00:04:09, T_speed: 0.241\n",
      "[Epoch  70] T_loss: 0.02145, T_accuracy: 99.2309 | V_loss: 0.44606, V_accuracy: 90.7200 | Early stopping counter: 6 out of 10 | T_time: 00:04:51, T_speed: 0.241\n",
      "[Epoch  80] T_loss: 0.01653, T_accuracy: 99.4000 | V_loss: 0.49910, V_accuracy: 90.1000 | Early stopping counter: 7 out of 10 | T_time: 00:05:32, T_speed: 0.241\n",
      "[Epoch  90] T_loss: 0.01374, T_accuracy: 99.5127 | V_loss: 0.54442, V_accuracy: 88.8600 | Early stopping counter: 8 out of 10 | T_time: 00:06:13, T_speed: 0.241\n",
      "[Epoch 100] T_loss: 0.01524, T_accuracy: 99.4636 | V_loss: 0.43362, V_accuracy: 91.0200 | Early stopping counter: 9 out of 10 | T_time: 00:06:55, T_speed: 0.241\n",
      "[Epoch 110] T_loss: 0.01338, T_accuracy: 99.5564 | V_loss: 0.47874, V_accuracy: 90.9800 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 00:07:36, T_speed: 0.241\n",
      "Final training time: 00:07:36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Training accuracy</td><td>▁▆▇▇████████</td></tr><tr><td>Training loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>█▄▂▁▂▁▂▁▂▂▂▂</td></tr><tr><td>Validation accuracy (%)</td><td>▁▇▇▇██▇██▇██</td></tr><tr><td>Validation loss</td><td>█▁▂▂▂▄▄▄▅▅▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>110</td></tr><tr><td>Training accuracy</td><td>99.55636</td></tr><tr><td>Training loss</td><td>0.01338</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.24123</td></tr><tr><td>Validation accuracy (%)</td><td>90.98</td></tr><tr><td>Validation loss</td><td>0.47874</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResnetModel</strong> at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/2ktz7942' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/2ktz7942</a><br/> View project at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241122_113350-2ktz7942/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'ResnetModel'\n",
    "wandb.init(\n",
    "    mode='online',\n",
    "    project=project_name,\n",
    "    notes='Fashion_MNIST with various models',\n",
    "    name=name,\n",
    "    config=config,\n",
    ")\n",
    "Resnet_model = get_resnet_model()\n",
    "Resnet_model.to(device)\n",
    "optimizer = torch.optim.Adam(Resnet_model.parameters(), lr=wandb.config.learning_rate)\n",
    "Resnet_checkout = os.path.join('checkpoint_resnet')\n",
    "classification_trainer = Trainer(\n",
    "    project_name=project_name,model=Resnet_model, optimizer=optimizer,train_data_loader=train_data_loader, validation_data_loader=validation_data_loader,\n",
    "    transforms=f_mnist_transforms, run_time_str=run_time_str,wandb=wandb,device=device,checkpoint_file_path=Resnet_checkout\n",
    ")\n",
    "classification_trainer.train_loop()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e9d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class second_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1, n_output=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LazyConv2d(out_channels=32, kernel_size=(3,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.LazyConv2d(out_channels=64, kernel_size=(3,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.LazyLinear(out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.LazyLinear(n_output),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def get_second_model():\n",
    "    model = second_model()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d087d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c5edf2a2524a2bafae8021531207d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112420095337762, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/link_dl/wandb/run-20241122_114550-dffx7l9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/dffx7l9m' target=\"_blank\">second_model</a></strong> to <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/dffx7l9m' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/dffx7l9m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 1.80080, T_accuracy: 71.6764 | V_loss: 1.74983, V_accuracy: 79.8600 | Early stopping is stated! | T_time: 00:00:02, T_speed: 0.500\n",
      "[Epoch  10] T_loss: 1.56010, T_accuracy: 90.6655 | V_loss: 1.55858, V_accuracy: 90.6400 | V_loss decreased (1.74983 --> 1.55858). Saving model... | T_time: 00:00:25, T_speed: 0.400\n",
      "[Epoch  20] T_loss: 1.54244, T_accuracy: 92.2000 | V_loss: 1.55332, V_accuracy: 91.0000 | V_loss decreased (1.55858 --> 1.55332). Saving model... | T_time: 00:00:51, T_speed: 0.392\n",
      "[Epoch  30] T_loss: 1.53213, T_accuracy: 93.2255 | V_loss: 1.54804, V_accuracy: 91.3800 | V_loss decreased (1.55332 --> 1.54804). Saving model... | T_time: 00:01:16, T_speed: 0.395\n",
      "[Epoch  40] T_loss: 1.52385, T_accuracy: 93.9982 | V_loss: 1.53840, V_accuracy: 92.6200 | V_loss decreased (1.54804 --> 1.53840). Saving model... | T_time: 00:01:42, T_speed: 0.392\n",
      "[Epoch  50] T_loss: 1.51854, T_accuracy: 94.5182 | V_loss: 1.53509, V_accuracy: 92.6400 | V_loss decreased (1.53840 --> 1.53509). Saving model... | T_time: 00:02:07, T_speed: 0.394\n",
      "[Epoch  60] T_loss: 1.51415, T_accuracy: 94.9164 | V_loss: 1.53327, V_accuracy: 92.8800 | V_loss decreased (1.53509 --> 1.53327). Saving model... | T_time: 00:02:33, T_speed: 0.392\n",
      "[Epoch  70] T_loss: 1.51076, T_accuracy: 95.2109 | V_loss: 1.53757, V_accuracy: 92.3400 | Early stopping counter: 1 out of 10 | T_time: 00:02:58, T_speed: 0.393\n",
      "[Epoch  80] T_loss: 1.50798, T_accuracy: 95.5073 | V_loss: 1.53554, V_accuracy: 92.6200 | Early stopping counter: 2 out of 10 | T_time: 00:03:23, T_speed: 0.394\n",
      "[Epoch  90] T_loss: 1.50664, T_accuracy: 95.6055 | V_loss: 1.53705, V_accuracy: 92.3400 | Early stopping counter: 3 out of 10 | T_time: 00:03:48, T_speed: 0.395\n",
      "[Epoch 100] T_loss: 1.50397, T_accuracy: 95.8327 | V_loss: 1.53654, V_accuracy: 92.4800 | Early stopping counter: 4 out of 10 | T_time: 00:04:14, T_speed: 0.394\n",
      "[Epoch 110] T_loss: 1.50126, T_accuracy: 96.1509 | V_loss: 1.52997, V_accuracy: 93.2000 | V_loss decreased (1.53327 --> 1.52997). Saving model... | T_time: 00:04:39, T_speed: 0.394\n",
      "[Epoch 120] T_loss: 1.50107, T_accuracy: 96.1182 | V_loss: 1.53079, V_accuracy: 93.0400 | Early stopping counter: 1 out of 10 | T_time: 00:05:04, T_speed: 0.395\n",
      "[Epoch 130] T_loss: 1.49966, T_accuracy: 96.3309 | V_loss: 1.53108, V_accuracy: 92.8800 | Early stopping counter: 2 out of 10 | T_time: 00:05:30, T_speed: 0.394\n",
      "[Epoch 140] T_loss: 1.49847, T_accuracy: 96.3945 | V_loss: 1.53043, V_accuracy: 93.1600 | Early stopping counter: 3 out of 10 | T_time: 00:05:55, T_speed: 0.394\n",
      "[Epoch 150] T_loss: 1.49602, T_accuracy: 96.6309 | V_loss: 1.52959, V_accuracy: 93.2600 | V_loss decreased (1.52997 --> 1.52959). Saving model... | T_time: 00:06:20, T_speed: 0.395\n",
      "[Epoch 160] T_loss: 1.49626, T_accuracy: 96.5818 | V_loss: 1.52885, V_accuracy: 93.2800 | V_loss decreased (1.52959 --> 1.52885). Saving model... | T_time: 00:06:45, T_speed: 0.395\n",
      "[Epoch 170] T_loss: 1.49407, T_accuracy: 96.8400 | V_loss: 1.52756, V_accuracy: 93.4200 | V_loss decreased (1.52885 --> 1.52756). Saving model... | T_time: 00:07:11, T_speed: 0.394\n",
      "[Epoch 180] T_loss: 1.49471, T_accuracy: 96.6836 | V_loss: 1.52850, V_accuracy: 93.2800 | Early stopping counter: 1 out of 10 | T_time: 00:07:36, T_speed: 0.395\n",
      "[Epoch 190] T_loss: 1.49326, T_accuracy: 96.8964 | V_loss: 1.52816, V_accuracy: 93.3200 | Early stopping counter: 2 out of 10 | T_time: 00:08:01, T_speed: 0.395\n",
      "[Epoch 200] T_loss: 1.49184, T_accuracy: 97.0345 | V_loss: 1.53108, V_accuracy: 93.0400 | Early stopping counter: 3 out of 10 | T_time: 00:08:27, T_speed: 0.394\n",
      "[Epoch 210] T_loss: 1.49091, T_accuracy: 97.1145 | V_loss: 1.52980, V_accuracy: 93.1600 | Early stopping counter: 4 out of 10 | T_time: 00:08:52, T_speed: 0.395\n",
      "[Epoch 220] T_loss: 1.49154, T_accuracy: 97.0236 | V_loss: 1.52964, V_accuracy: 93.1000 | Early stopping counter: 5 out of 10 | T_time: 00:09:17, T_speed: 0.395\n",
      "[Epoch 230] T_loss: 1.48983, T_accuracy: 97.2109 | V_loss: 1.53065, V_accuracy: 93.0200 | Early stopping counter: 6 out of 10 | T_time: 00:09:42, T_speed: 0.395\n",
      "[Epoch 240] T_loss: 1.49063, T_accuracy: 97.1127 | V_loss: 1.52935, V_accuracy: 93.1600 | Early stopping counter: 7 out of 10 | T_time: 00:10:07, T_speed: 0.395\n",
      "[Epoch 250] T_loss: 1.48937, T_accuracy: 97.2618 | V_loss: 1.52874, V_accuracy: 93.0400 | Early stopping counter: 8 out of 10 | T_time: 00:10:33, T_speed: 0.395\n",
      "[Epoch 260] T_loss: 1.49023, T_accuracy: 97.1618 | V_loss: 1.52947, V_accuracy: 93.0800 | Early stopping counter: 9 out of 10 | T_time: 00:10:58, T_speed: 0.395\n",
      "[Epoch 270] T_loss: 1.48762, T_accuracy: 97.4564 | V_loss: 1.52749, V_accuracy: 93.2000 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 00:11:23, T_speed: 0.395\n",
      "Final training time: 00:11:23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>Training accuracy</td><td>▁▆▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>Training loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation accuracy (%)</td><td>▁▇▇▇███▇█▇██████████████████</td></tr><tr><td>Validation loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>270</td></tr><tr><td>Training accuracy</td><td>97.45636</td></tr><tr><td>Training loss</td><td>1.48762</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.39531</td></tr><tr><td>Validation accuracy (%)</td><td>93.2</td></tr><tr><td>Validation loss</td><td>1.52749</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">second_model</strong> at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/dffx7l9m' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/dffx7l9m</a><br/> View project at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241122_114550-dffx7l9m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'second_model'\n",
    "wandb.init(\n",
    "    mode='online',\n",
    "    project=project_name,\n",
    "    notes='Fashion_MNIST with various models',\n",
    "    name=name,\n",
    "    config=config,\n",
    ")\n",
    "second_model_test = get_second_model()\n",
    "second_model_test.to(device)\n",
    "#Adam 옵티마이저 사용(beta1 = 0.9, beta2 = 0.999)\n",
    "optimizer = torch.optim.Adam(second_model_test.parameters(), lr=wandb.config.learning_rate, betas=(0.9, 0.999))\n",
    "#딥러닝 모델 저장 path\n",
    "second_checkout = os.path.join('checkpoint_second')\n",
    "#Trainer 객체 생성\n",
    "classification_trainer = Trainer(\n",
    "    project_name=project_name,model=second_model_test, optimizer=optimizer,train_data_loader=train_data_loader, validation_data_loader=validation_data_loader,\n",
    "    transforms=f_mnist_transforms, run_time_str=run_time_str,wandb=wandb,device=device,checkpoint_file_path=second_checkout\n",
    ")\n",
    "#학습 시작\n",
    "classification_trainer.train_loop()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecc82857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "second_model                             --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "├─Sequential: 1-1                        --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "│    └─Conv2d: 2-1                       [3, 3]                    [1, 1, 28, 28]            [1, 32, 26, 26]           320                       216,320\n",
       "│    └─ReLU: 2-2                         --                        [1, 32, 26, 26]           [1, 32, 26, 26]           --                        --\n",
       "│    └─BatchNorm2d: 2-3                  --                        [1, 32, 26, 26]           [1, 32, 26, 26]           64                        64\n",
       "│    └─Dropout: 2-4                      --                        [1, 32, 26, 26]           [1, 32, 26, 26]           --                        --\n",
       "│    └─MaxPool2d: 2-5                    [2, 2]                    [1, 32, 26, 26]           [1, 32, 13, 13]           --                        --\n",
       "│    └─Conv2d: 2-6                       [3, 3]                    [1, 32, 13, 13]           [1, 64, 11, 11]           18,496                    2,238,016\n",
       "│    └─ReLU: 2-7                         --                        [1, 64, 11, 11]           [1, 64, 11, 11]           --                        --\n",
       "│    └─MaxPool2d: 2-8                    [2, 2]                    [1, 64, 11, 11]           [1, 64, 5, 5]             --                        --\n",
       "│    └─Flatten: 2-9                      --                        [1, 64, 5, 5]             [1, 1600]                 --                        --\n",
       "│    └─Dropout: 2-10                     --                        [1, 1600]                 [1, 1600]                 --                        --\n",
       "│    └─Linear: 2-11                      --                        [1, 1600]                 [1, 128]                  204,928                   204,928\n",
       "│    └─ReLU: 2-12                        --                        [1, 128]                  [1, 128]                  --                        --\n",
       "│    └─BatchNorm1d: 2-13                 --                        [1, 128]                  [1, 128]                  256                       256\n",
       "│    └─Dropout: 2-14                     --                        [1, 128]                  [1, 128]                  --                        --\n",
       "│    └─Linear: 2-15                      --                        [1, 128]                  [1, 10]                   1,290                     1,290\n",
       "│    └─Softmax: 2-16                     --                        [1, 10]                   [1, 10]                   --                        --\n",
       "=====================================================================================================================================================================\n",
       "Total params: 225,354\n",
       "Trainable params: 225,354\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.66\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.41\n",
       "Params size (MB): 0.90\n",
       "Estimated Total Size (MB): 1.31\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=second_model_test, input_size=(1, 1, 28, 28),\n",
    "        col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], dtypes=[torch.float] )"
   ]
  },
  {
   "cell_type": "code",
   "id": "af9d56c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:47:09.295756Z",
     "start_time": "2024-11-22T15:47:09.283754Z"
    }
   },
   "source": [
    "class third_model(nn.Module):\n",
    "    def __init__(self, input_channels = 1, n_output=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=(3,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.LazyConv2d(out_channels=32, kernel_size=(3,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.LazyConv2d(out_channels=64, kernel_size=(3,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(128),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(n_output),\n",
    "            nn.Softmax(),\n",
    "            \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "            \n",
    "    \n",
    "def get_third_model():\n",
    "    model = third_model()\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bbbbc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6037105e1c1418891dc80349f91376e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113115068938997, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/link_dl/wandb/run-20241122_120057-l1igllu4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/l1igllu4' target=\"_blank\">third_model</a></strong> to <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/l1igllu4' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/l1igllu4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] T_loss: 1.78634, T_accuracy: 72.9036 | V_loss: 1.79341, V_accuracy: 72.6400 | Early stopping is stated! | T_time: 00:00:03, T_speed: 0.333\n",
      "[Epoch  10] T_loss: 1.54912, T_accuracy: 91.6382 | V_loss: 1.54510, V_accuracy: 91.7000 | V_loss decreased (1.79341 --> 1.54510). Saving model... | T_time: 00:00:28, T_speed: 0.357\n",
      "[Epoch  20] T_loss: 1.52697, T_accuracy: 93.6455 | V_loss: 1.53253, V_accuracy: 93.0000 | V_loss decreased (1.54510 --> 1.53253). Saving model... | T_time: 00:00:56, T_speed: 0.357\n",
      "[Epoch  30] T_loss: 1.51625, T_accuracy: 94.6745 | V_loss: 1.53285, V_accuracy: 92.8800 | Early stopping counter: 1 out of 10 | T_time: 00:01:24, T_speed: 0.357\n",
      "[Epoch  40] T_loss: 1.50851, T_accuracy: 95.4200 | V_loss: 1.52623, V_accuracy: 93.5200 | V_loss decreased (1.53253 --> 1.52623). Saving model... | T_time: 00:01:52, T_speed: 0.357\n",
      "[Epoch  50] T_loss: 1.50158, T_accuracy: 96.0455 | V_loss: 1.52554, V_accuracy: 93.6200 | V_loss decreased (1.52623 --> 1.52554). Saving model... | T_time: 00:02:21, T_speed: 0.355\n",
      "[Epoch  60] T_loss: 1.49615, T_accuracy: 96.6018 | V_loss: 1.52646, V_accuracy: 93.6200 | Early stopping counter: 1 out of 10 | T_time: 00:02:49, T_speed: 0.355\n",
      "[Epoch  70] T_loss: 1.49187, T_accuracy: 96.9982 | V_loss: 1.52349, V_accuracy: 93.6800 | V_loss decreased (1.52554 --> 1.52349). Saving model... | T_time: 00:03:18, T_speed: 0.354\n",
      "[Epoch  80] T_loss: 1.48949, T_accuracy: 97.2636 | V_loss: 1.52200, V_accuracy: 94.0200 | V_loss decreased (1.52349 --> 1.52200). Saving model... | T_time: 00:03:46, T_speed: 0.354\n",
      "[Epoch  90] T_loss: 1.49232, T_accuracy: 96.9618 | V_loss: 1.52566, V_accuracy: 93.5800 | Early stopping counter: 1 out of 10 | T_time: 00:04:15, T_speed: 0.353\n",
      "[Epoch 100] T_loss: 1.48632, T_accuracy: 97.5509 | V_loss: 1.52363, V_accuracy: 93.7200 | Early stopping counter: 2 out of 10 | T_time: 00:04:43, T_speed: 0.353\n",
      "[Epoch 110] T_loss: 1.48513, T_accuracy: 97.6273 | V_loss: 1.52337, V_accuracy: 93.8400 | Early stopping counter: 3 out of 10 | T_time: 00:05:11, T_speed: 0.354\n",
      "[Epoch 120] T_loss: 1.48164, T_accuracy: 97.9909 | V_loss: 1.52176, V_accuracy: 93.9600 | V_loss decreased (1.52200 --> 1.52176). Saving model... | T_time: 00:05:39, T_speed: 0.354\n",
      "[Epoch 130] T_loss: 1.48064, T_accuracy: 98.0855 | V_loss: 1.52013, V_accuracy: 93.9800 | V_loss decreased (1.52176 --> 1.52013). Saving model... | T_time: 00:06:08, T_speed: 0.353\n",
      "[Epoch 140] T_loss: 1.47983, T_accuracy: 98.1618 | V_loss: 1.52168, V_accuracy: 93.9800 | Early stopping counter: 1 out of 10 | T_time: 00:06:36, T_speed: 0.354\n",
      "[Epoch 150] T_loss: 1.47861, T_accuracy: 98.2800 | V_loss: 1.52166, V_accuracy: 93.8000 | Early stopping counter: 2 out of 10 | T_time: 00:07:04, T_speed: 0.354\n",
      "[Epoch 160] T_loss: 1.47705, T_accuracy: 98.4509 | V_loss: 1.52038, V_accuracy: 94.0800 | Early stopping counter: 3 out of 10 | T_time: 00:07:33, T_speed: 0.353\n",
      "[Epoch 170] T_loss: 1.47687, T_accuracy: 98.4509 | V_loss: 1.52239, V_accuracy: 93.8200 | Early stopping counter: 4 out of 10 | T_time: 00:08:01, T_speed: 0.353\n",
      "[Epoch 180] T_loss: 1.47543, T_accuracy: 98.6018 | V_loss: 1.52008, V_accuracy: 94.1600 | Early stopping counter: 5 out of 10 | T_time: 00:08:29, T_speed: 0.354\n",
      "[Epoch 190] T_loss: 1.47613, T_accuracy: 98.5164 | V_loss: 1.52205, V_accuracy: 93.8800 | Early stopping counter: 6 out of 10 | T_time: 00:08:57, T_speed: 0.354\n",
      "[Epoch 200] T_loss: 1.47445, T_accuracy: 98.6673 | V_loss: 1.52301, V_accuracy: 93.7200 | Early stopping counter: 7 out of 10 | T_time: 00:09:24, T_speed: 0.355\n",
      "[Epoch 210] T_loss: 1.47463, T_accuracy: 98.6673 | V_loss: 1.52085, V_accuracy: 94.0200 | Early stopping counter: 8 out of 10 | T_time: 00:09:53, T_speed: 0.354\n",
      "[Epoch 220] T_loss: 1.47426, T_accuracy: 98.7164 | V_loss: 1.52220, V_accuracy: 93.9800 | Early stopping counter: 9 out of 10 | T_time: 00:10:21, T_speed: 0.354\n",
      "[Epoch 230] T_loss: 1.47314, T_accuracy: 98.8255 | V_loss: 1.52048, V_accuracy: 94.0400 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 00:10:50, T_speed: 0.354\n",
      "Final training time: 00:10:50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>Training accuracy</td><td>▁▆▇▇▇▇▇██▇██████████████</td></tr><tr><td>Training loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Validation accuracy (%)</td><td>▁▇██████████████████████</td></tr><tr><td>Validation loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>230</td></tr><tr><td>Training accuracy</td><td>98.82545</td></tr><tr><td>Training loss</td><td>1.47314</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.35385</td></tr><tr><td>Validation accuracy (%)</td><td>94.04</td></tr><tr><td>Validation loss</td><td>1.52048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">third_model</strong> at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/l1igllu4' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST/runs/l1igllu4</a><br/> View project at: <a href='https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST' target=\"_blank\">https://wandb.ai/kjs0820k-korea-university-of-technology-and-education/Fashion_MNIST</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241122_120057-l1igllu4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'third_model'\n",
    "wandb.init(\n",
    "    mode='online',\n",
    "    project=project_name,\n",
    "    notes='Fashion_MNIST with various models',\n",
    "    name=name,\n",
    "    config=config,\n",
    ")\n",
    "third_model_test = get_third_model()\n",
    "third_model_test.to(device)\n",
    "#Adam 옵티마이저 사용(beta1 = 0.9, beta2 = 0.999)\n",
    "optimizer = torch.optim.Adam(third_model_test.parameters(), lr=wandb.config.learning_rate, betas=(0.9, 0.999))\n",
    "#딥러닝 모델 저장하기 위한 path\n",
    "third_checkout = os.path.join('checkpoint_third')\n",
    "#Trainer 객체 생성\n",
    "classification_trainer = Trainer(\n",
    "    project_name=project_name,model=third_model_test, optimizer=optimizer,train_data_loader=train_data_loader, validation_data_loader=validation_data_loader,\n",
    "    transforms=f_mnist_transforms, run_time_str=run_time_str,wandb=wandb,device=device,checkpoint_file_path=third_checkout\n",
    ")\n",
    "#학습 시작\n",
    "classification_trainer.train_loop()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74658dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "second_model                             --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "├─Sequential: 1-1                        --                        [1, 1, 28, 28]            [1, 10]                   --                        --\n",
       "│    └─Conv2d: 2-1                       [3, 3]                    [1, 1, 28, 28]            [1, 32, 26, 26]           320                       216,320\n",
       "│    └─ReLU: 2-2                         --                        [1, 32, 26, 26]           [1, 32, 26, 26]           --                        --\n",
       "│    └─BatchNorm2d: 2-3                  --                        [1, 32, 26, 26]           [1, 32, 26, 26]           64                        64\n",
       "│    └─Dropout: 2-4                      --                        [1, 32, 26, 26]           [1, 32, 26, 26]           --                        --\n",
       "│    └─MaxPool2d: 2-5                    [2, 2]                    [1, 32, 26, 26]           [1, 32, 13, 13]           --                        --\n",
       "│    └─Conv2d: 2-6                       [3, 3]                    [1, 32, 13, 13]           [1, 64, 11, 11]           18,496                    2,238,016\n",
       "│    └─ReLU: 2-7                         --                        [1, 64, 11, 11]           [1, 64, 11, 11]           --                        --\n",
       "│    └─MaxPool2d: 2-8                    [2, 2]                    [1, 64, 11, 11]           [1, 64, 5, 5]             --                        --\n",
       "│    └─Flatten: 2-9                      --                        [1, 64, 5, 5]             [1, 1600]                 --                        --\n",
       "│    └─Dropout: 2-10                     --                        [1, 1600]                 [1, 1600]                 --                        --\n",
       "│    └─Linear: 2-11                      --                        [1, 1600]                 [1, 128]                  204,928                   204,928\n",
       "│    └─ReLU: 2-12                        --                        [1, 128]                  [1, 128]                  --                        --\n",
       "│    └─BatchNorm1d: 2-13                 --                        [1, 128]                  [1, 128]                  256                       256\n",
       "│    └─Dropout: 2-14                     --                        [1, 128]                  [1, 128]                  --                        --\n",
       "│    └─Linear: 2-15                      --                        [1, 128]                  [1, 10]                   1,290                     1,290\n",
       "│    └─Softmax: 2-16                     --                        [1, 10]                   [1, 10]                   --                        --\n",
       "=====================================================================================================================================================================\n",
       "Total params: 225,354\n",
       "Trainable params: 225,354\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.66\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.41\n",
       "Params size (MB): 0.90\n",
       "Estimated Total Size (MB): 1.31\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=second_model_test, input_size=(1, 1, 28, 28),\n",
    "        col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], dtypes=[torch.float] )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Learning Rate는 0.001    \n",
    "### Batch Size는 128개  \n",
    "### Early Stop Patience의 경우 validation이 10번동안 안떨어지면 종료하도록함\n",
    "### Weight_decay는 사용하지 않았습니다.\n",
    "### Normalization은 매 컨볼루션 층에는 Relu 후에 BatchNormalization 2d가 사용되었고 Linear에서는 마지막 10개의 채널 구하기 전에 BatchNormalization 1d를 사용하였습니다.\n",
    "### Dropout의 경우 매 컨볼루션 층에서 0.3을 주고 Flatten이후에는 LinearLayout에서는 0.5를 주었습니다. \n",
    "### 추가적으로 optimizer는 Adam을 사용했고 beta1 = 0.9, beta2 = 0.999를 사용했습니다. \n",
    "### Validation Accuracy 94.04가 나왔습니다."
   ],
   "id": "cb755f5a8f7b2561"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<H1>[문제 3]학습 완료된 모델로 테스트 데이터 Accuracy 확인하기",
   "id": "e0258b8b53df1b70"
  },
  {
   "cell_type": "code",
   "id": "68deea5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:46:23.559656Z",
     "start_time": "2024-11-22T15:46:23.104554Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#ClassificationTester를 참고하여 tester클래서 정의\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, project_name, model, test_data_loader, transforms, checkpoint_file_path):\n",
    "        self.project_name = project_name\n",
    "        self.test_data_loader = test_data_loader\n",
    "        self.transforms = transforms\n",
    "        self.latest_file_path = os.path.join(checkpoint_file_path, f'{project_name}_checkpoint_latest.pt')\n",
    "        self.model = model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        \n",
    "        print(\"MODEL FILE: {0}\".format(self.latest_file_path))\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(self.latest_file_path, map_location=self.device))\n",
    "        self.all_images = []\n",
    "        self.all_labels = []\n",
    "        self.all_predictions = []\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        num_correct = 0\n",
    "        num_tested_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_data_loader:\n",
    "                if self.transforms:\n",
    "                    images = self.transforms(images)\n",
    "                \n",
    "                test_output = self.model(images)\n",
    "                test_predicted = torch.argmax(test_output, dim=-1)\n",
    "                num_correct += (test_predicted == labels).sum().item()\n",
    "                num_tested_samples += len(labels)\n",
    "                #이미지 저장해주기 \n",
    "                self.all_images.append(images.cpu())\n",
    "                self.all_labels.append(labels.cpu())\n",
    "                self.all_predictions.append(test_predicted.cpu())\n",
    "                \n",
    "            test_accuracy = 100.0 * num_correct / num_tested_samples\n",
    "        \n",
    "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    def visualize_random_predictions(self):\n",
    "        #label index별 이름\n",
    "        label_names = [\n",
    "            \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "            \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "        ]\n",
    "        #모든 image, label, predicted_label를 0차원을 기준으로 합치기\n",
    "        images = torch.cat(self.all_images, dim=0)\n",
    "        labels = torch.cat(self.all_labels, dim=0)\n",
    "        predictions = torch.cat(self.all_predictions, dim=0)\n",
    "\n",
    "        #random 하게 10개 선택\n",
    "        indices = torch.randperm(len(images))[:10]\n",
    "        #선택된 이미지들 라스트 저장\n",
    "        selected_images = images[indices]\n",
    "        selected_labels = labels[indices]\n",
    "        selected_predictions = predictions[indices]\n",
    "\n",
    "        # Plot the samples\n",
    "        fig, axes = plt.subplots(1, 10, figsize=(20, 3))\n",
    "        for i, ax in enumerate(axes):\n",
    "            #channel demension을 없애기 위해 squeeze()함수 실행\n",
    "            img = selected_images[i].squeeze().numpy()  \n",
    "            #아까 만든 label 이름과 선택된 prediction과 매칭\n",
    "            predicted_name = label_names[selected_predictions[i].item()]\n",
    "            #아까 만든 label 이름과 선택된 실제 label과 매칭\n",
    "            actual_name = label_names[selected_labels[i].item()]\n",
    "            #이미지 10개 보여주기\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f\"P: {predicted_name}\\nL: {actual_name}\")\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b7814db2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:47:41.173885Z",
     "start_time": "2024-11-22T15:47:35.839694Z"
    }
   },
   "source": [
    "f_mnist_test_images, f_mnist_test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()\n",
    "third_checkout = os.path.join('checkpoint_third')\n",
    "project_name = 'Fashion_MNIST'\n",
    "test_model = get_third_model()\n",
    "classification_Tester = Tester(project_name, test_model, f_mnist_test_data_loader, f_mnist_transforms, third_checkout)\n",
    "classification_Tester.test()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Test Samples:  10000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "MODEL FILE: checkpoint_third\\Fashion_MNIST_checkpoint_latest.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinsung\\AppData\\Local\\Temp\\ipykernel_13660\\657986583.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.latest_file_path, map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.33%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<H3> Test Accuracy: 93.33%가 나왔습니다",
   "id": "ecc36f9bf74ce8a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<H1>[문제 4]샘플 테스트 데이터 분류 예측 결과 확인하기 ",
   "id": "f1ef52aa57147627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:48:06.261793Z",
     "start_time": "2024-11-22T15:48:05.872706Z"
    }
   },
   "cell_type": "code",
   "source": "classification_Tester.visualize_random_predictions()",
   "id": "daba8d3ebd98e34d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x300 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h4>2번째 있는 것이 기존 label이 Shirt인데 T-Shirt/top로 나왔는데 육안으로 확인해도 shirt보다는 T-shirt라고 생각이 들 정도로 화질이 좋지 않아서 Shirt와 T-Shirt/top에 대한 구분을 확실하게 하지 못한것 같습니다. 또한 전반적으로fashion_mnist의 pixel이 28*28이다 보니 화질이 좋지않아서 상의 계열, 하의 계열, 신발 계열등은 잘 분리하는데 상의 계열 내부적으로는 구분을 정확히 하기 힘들것 같습니다. 이 경우의 화질이 조금은 더 좋은 데이터로 학습을 한다면 이보다 더 구분을 잘할 수 있다고 생각합니다.",
   "id": "7f8f5512f7e01f6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<H1>숙제 후기",
   "id": "698191741f7db26f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이번 과제를 진행하면서 하이퍼 파라미터 조정하는게 딥러닝에서 엄청나게 중요하구나라는 것을 알았습니다. 실제로 같은 모델에서도 하이퍼파라미터를 변경을 자주 진행하였습니다. 그리고 또한 Dropout, BatchNormalization을 주는 위치, 강도등을 변경을 하면서도 진행했는데 확실히 성능이 큰폭으로 변화가 있었습니다. 이번에는 backend ai환경에서 진행했는데 집에서 3080쓰고 학습을 진행해봤는데 너무 오래걸려서 중간에 중단한 적도 있습니다. 확실히 이번에 학교에서 제공해준 환경이 많은 도움과 시간 단축이 되었습니다. 이 Fashion MNIST는 실제 사진보다는 feature가 많지 않아서 그런지 다른 ResNet, Vgg같은 것을 써보았는데 확실히 성능이 좋지 않았습니다. 그래서 Fashion MNIST는 흑백이미지이지만 다른 색 이미지에 화질이 조금 더 많은 이미지를 통해서 학습을 해보면 더 좋을 것 같습니다.",
   "id": "cd77577c9f6cfce8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d1609b52379e4656"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.3 (NGC 24.03/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
